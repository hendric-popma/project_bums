{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "from tools import user_input, audio_output, FrameObject, FindDirection, Segmentation\n",
    "\n",
    "global_res_text = 0\n",
    "global_previous_text = 0\n",
    "\n",
    "\n",
    "# Video-Thread\n",
    "def video_thread( video, line_color, total_frames):\n",
    "\n",
    "    global global_res_text\n",
    "    plt.gray()\n",
    "    \n",
    "    # init class/values for while loop\n",
    "    direct = FindDirection()\n",
    "\n",
    "    while video.isOpened():\n",
    "        # Read a single frame\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            print(\"Error load frame\")\n",
    "            break\n",
    "\n",
    "        #Create a Frame Object\n",
    "        frame = FrameObject(frame)\n",
    "        #get image from FrameObject\n",
    "        img = frame.img\n",
    "        #Create Segmemtation Object  \n",
    "        seg = Segmentation(frame, line_color)\n",
    "        #get the orientation line\n",
    "        img_seg = seg.get_orientation_lines()\n",
    "        frame.build_center_line(img_seg)\n",
    "        #used later to find the directions\n",
    "        img = frame.make_block_over_center_line()\n",
    "        \n",
    "        # Get Values from FrameObject to Direction Object\n",
    "        direct.get_values_from_frame_object(frame)\n",
    "        direct.wait_for_complete_contour(img)\n",
    "        direct.find_nearest_line(img_seg)\n",
    "        direct.check_where_to_go()\n",
    "        res_text = direct.smooth_output()\n",
    "        global_res_text = res_text\n",
    "        frame.text_in_frame(res_text)\n",
    "        frame_show = frame.overlay_segmentation(img_seg)\n",
    "\n",
    "        cv2.imshow('Processed Frame',frame_show)\n",
    "\n",
    "        # Check for key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if video.get(cv2.CAP_PROP_POS_FRAMES) == total_frames:\n",
    "            break\n",
    "    # Release the video objects and close the windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Audio-Thread\n",
    "def audio_thread():\n",
    "\n",
    "    global global_res_text\n",
    "    global global_previous_text\n",
    "\n",
    "    while video.isOpened():\n",
    "        # Read a single frame\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            print(\"Error load frame\")\n",
    "            break\n",
    "        \n",
    "        # Überprüfen, ob sich das letzte Element geändert hat\n",
    "        if global_res_text != \" 0\" and global_res_text != \" \":\n",
    "            if global_res_text != global_previous_text:\n",
    "                global_previous_text = global_res_text\n",
    "                audio_output(global_res_text)   \n",
    "\n",
    "        time.sleep(0.0005)         \n",
    "        \n",
    "     # Check for key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        if video.get(cv2.CAP_PROP_POS_FRAMES) == total_frames:\n",
    "            break\n",
    "    # Release the video objects and close the windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    " \n",
    "video, line_color, total_frames = user_input()\n",
    "\n",
    "# Threads starten\n",
    "video_thread = threading.Thread(target=video_thread, args=(video, line_color, total_frames))\n",
    "audio_thread = threading.Thread(target=audio_thread)\n",
    "\n",
    "video_thread.start()\n",
    "audio_thread.start()\n",
    "\n",
    "video_thread.join()\n",
    "audio_thread.join()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
